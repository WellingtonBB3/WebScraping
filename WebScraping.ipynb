{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Actividad extracurricular 12] web scraping\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nombre:** Wellington Barros  \n",
    "**Fecha:** 04/01/2025  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Revisar qué es web scraping**  \n",
    "¿Qué es el Web Scraping?  \n",
    "Es un proceso automatizado que sirve para extraer datos de sitios web mediante programas informaticos conocidos como scrapers. Estos programas recopilan y estructuran la información disponible en la web, facilitando su análisis y uso.  \n",
    "  \n",
    "**Usos comunes del Web Scraping** \n",
    "1. Estudio de mercado: Permite analizar precios, tendencias y estrategias de competidores.  \n",
    "2. Automatización empresarial: Optimiza tareas como la recopilación de datos masivos.\n",
    "3. Generación de leads: Facilita la creación de listas de clientes potenciales.\n",
    "4. Seguimiento de precios: Extrae datos de precios para comparar o analizar fluctuaciones.\n",
    "5. Noticias y contenidos: Agrega información relevante para el seguimiento de tendencias.\n",
    "6. Inmobiliaria: Recopila listados de propiedades y analiza el mercado inmobiliario  \n",
    "  \n",
    "**Funcionamiento del Web scraping**  \n",
    "El proceso de web scraping consta de dos componentes principales:  \n",
    "\n",
    "* Crawlers: Navegan por la web para identificar y acceder al contenido objetivo.\n",
    "* Scrapers: Extraen datos específicos utilizando herramientas como expresiones regulares, XPath o selectores CSS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Realizar una prueba en python para dos librerías diferentes**  \n",
    "Para realizar este proceso se instaló las librerias BeautifulSoup y lxml  \n",
    "Se uso los siguiente comandos en terminal para cada caso:  \n",
    "pip install requests beautifulsoup4  \n",
    "pip install lxml requests\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Prueba en Pyhton con la libreria BeautifulSoup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título extraído con BeautifulSoup: ¿Qué es el web scraping?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL del sitio a extraer datos\n",
    "url = \"https://www.ionos.com/es-us/digitalguide/paginas-web/desarrollo-web/que-es-el-web-scraping/?srsltid=AfmBOoq53cVOp9i1SbdXmtA8cZ8t5rREeJdgpx4dI8zDNS8JkOP2_KwK\"\n",
    "\n",
    "# Hacer una solicitud HTTP\n",
    "response = requests.get(url)\n",
    "\n",
    "# Crear un objeto BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extraer un título de ejemplo\n",
    "titulo = soup.find(\"h1\").text\n",
    "print(\"Título extraído con BeautifulSoup:\", titulo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este primer ejemplo utilice la biblioteca BeatifulSoup para iniciar un web scraping sencillo en una pagina web de IONOS. Pimero se realiza una solicitud HTTP a la URL del articulo usando la biblioteca requests. Con esto extraje contenido de la pagina web con BeautifulSoup en este caso el titulo principal de la pagina \"h1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Prueba en Python con la libreria lxml**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título de la página: Algoritmo de Dijkstra: ¿Qué es y para qué sirve?\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "url = 'https://tfgonline.es/algoritmo-de-dijkstra/'\n",
    "response = requests.get(url)\n",
    "\n",
    "tree = html.fromstring(response.content)\n",
    "titulo = tree.xpath('//title/text()')[0]\n",
    "print(f'Título de la página: {titulo}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero se realiza una solicitud HTTP a la página web utilizando la librería requests. Luego, el contenido HTML de la página se procesa usando lxml y su módulo html, que convierte el HTML en un árbol de elementos. Usamos la función xpath() para extraer el contenido del título de la página, seleccionando el texto dentro de la etiqueta <title>. Finalmente, el título extraído se imprime en la consola. lxml es una librería eficiente y rápida para analizar HTML y XML, y el uso de XPath facilita la navegación y extracción de datos específicos dentro del contenido web."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
